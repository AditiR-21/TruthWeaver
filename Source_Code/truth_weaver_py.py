# -*- coding: utf-8 -*-
"""truth_weaver.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NXD-L4qf94VJh-Ka7IkOfFXKbmFxyO3v
"""

from getpass import getpass

# OpenRouter API key
OR_TOKEN = getpass("Enter your OpenRouter API key: ")

# Base URL for inference
API_URL = "https://openrouter.ai/api/v1/chat/completions"

headers = {
    "Authorization": f"Bearer {OR_TOKEN}",
    "Content-Type": "application/json",
}

import requests

def call_openrouter(prompt, max_tokens=600, temperature=0.0,
                    model="mistralai/mistral-7b-instruct:free"):
    """
    Sends a prompt to OpenRouter and returns the model's reply.
    """
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": "You are the Truth Weaver. Extract lies and truths in mystical JSON format."},
            {"role": "user", "content": prompt},
        ],
        "temperature": temperature,
        "max_tokens": max_tokens,
    }

    r = requests.post(API_URL, headers=headers, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"OpenRouter API error {r.status_code}: {r.text}")

    data = r.json()
    return data["choices"][0]["message"]["content"]

# Cell 2 - upload transcript.txt
from google.colab import files
import io, sys

print("Please upload transcript.txt (choose the file from your computer).")
uploaded = files.upload()

transcript_text = None
transcript_filename = None
for fn in uploaded:
    if fn.lower().endswith('.txt'):
        transcript_filename = fn
        transcript_text = io.open(fn, 'r', encoding='utf-8').read()
        break

if transcript_text is None:
    raise SystemExit("No .txt uploaded. Upload transcript.txt and run this cell again.")

print(f"Loaded {transcript_filename} — {len(transcript_text.splitlines())} lines")

with open("transcript.txt", "r", encoding="utf-8") as f:
    transcripts = f.read()

print("Transcript loaded. Length (chars):", len(transcripts))

subject = "atlas_2025"

prompt = f"""
You are the Truth Weaver. Analyze the subject "{subject}" based only on their transcript.

Transcript:
{transcripts}

Present your findings in this mystical format:

{{
  "shadow_id": "{subject}",
  "revealed_truth": {{
    "programming_experience": "string",
    "programming_language": "string",
    "skill_mastery": "string",
    "leadership_claims": "string",
    "team_experience": "string",
    "skills and other keywords": ["List[String]"]
  }},
  "deception_patterns": [{{
    "lie_type": "string",
    "contradictory_claims": ["List[String]"]
  }}]
}}
"""
print(prompt[:1000], "...\n\n")  # preview first 1000 chars

output_text = call_openrouter(prompt)
print("Raw model output:\n", output_text[:1000], "...\n\n")

subjects = [
    'atlas_2025', 'buried_confession', 'crius_2025',
    'drifted_anecdote', 'eos_2023', 'hedge_and_dodge',
    'hyperion_2022', 'oceanus_2022', 'rehearsed_evasion',
    'rhea_2024', 'selene_2024', 'selfcorrect_contradictions',
    'titan_2023'
]

results = {}

for subj in subjects:
    print(f"Processing: {subj} ...")
    prompt = f"""
    You are the Truth Weaver. Analyze the subject "{subj}" based only on their transcript.

    Transcript:
    {transcripts}

    Present your findings in this mystical format:

    {{
      "shadow_id": "{subj}",
      "revealed_truth": {{
        "programming_experience": "string",
        "programming_language": "string",
        "skill_mastery": "string",
        "leadership_claims": "string",
        "team_experience": "string",
        "skills and other keywords": ["List[String]"]
      }},
      "deception_patterns": [{{
        "lie_type": "string",
        "contradictory_claims": ["List[String]"]
      }}]
    }}
    """
    try:
        output_text = call_openrouter(prompt)
        results[subj] = output_text
    except Exception as e:
        results[subj] = f"Error: {str(e)}"

import json

with open("presubmission.json", "w", encoding="utf-8") as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print("✅ presubmission.json created successfully!")

import json
import re

# Load the raw submission.json
with open("presubmission.json", "r", encoding="utf-8") as f:
    raw_data = f.read()

# Step 1: Remove ```json ... ``` wrappers
raw_data = re.sub(r"```json\s*", "", raw_data)
raw_data = re.sub(r"```", "", raw_data)

# Step 2: Parse JSON (it may still be dict with string values)
data = json.loads(raw_data)

cleaned = []

for shadow_id, block in data.items():
    # If block is a string, parse it into JSON
    if isinstance(block, str):
        block = block.strip()
        try:
            block = json.loads(block)
        except json.JSONDecodeError:
            print(f"⚠️ Could not parse block for {shadow_id}")
            continue

    # Fix key name: skills_and_other_keywords → skills and other keywords
    if "revealed_truth" in block:
        rt = block["revealed_truth"]
        if "skills_and_other_keywords" in rt:
            rt["skills and other keywords"] = rt.pop("skills_and_other_keywords")

    # Ensure all required keys exist
    for key in ["programming_experience", "programming_language", "skill_mastery",
                "leadership_claims", "team_experience", "skills and other keywords"]:
        if key not in block["revealed_truth"]:
            block["revealed_truth"][key] = ""

    # Add shadow_id field
    block["shadow_id"] = shadow_id

    cleaned.append(block)

# Step 3: Save as array of objects
with open("submission.json", "w", encoding="utf-8") as f:
    json.dump(cleaned, f, indent=2, ensure_ascii=False)

print("✅ Cleaned JSON saved as submission.json")

from google.colab import files
files.download("submission.json")